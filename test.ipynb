{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b9eff47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sounddevice as sd\n",
    "import whisper\n",
    "from scipy.io.wavfile import write\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4b3e2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record():\n",
    "    freq = 44100\n",
    "    duration = 60\n",
    "    print(\"Recording...\")\n",
    "    recording = sd.rec(int(duration * freq), samplerate=freq, channels=1)\n",
    "    sd.wait()\n",
    "    write(\"recording.wav\", freq, recording)\n",
    "    return \"recording.wav\"\n",
    "\n",
    "# def transcribe():\n",
    "#     model_w = whisper.load_model(\"small\")\n",
    "#     result = model_w.transcribe(\"recording.wav\")\n",
    "#     trans_text = result[\"text\"]\n",
    "#     print(\"Transcription:\", trans_text)\n",
    "#     return trans_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c12dea05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe():\n",
    "    model_w = whisper.load_model(\"large\",device=\"cuda\")\n",
    "    result = model_w.transcribe(\"recording.wav\", task=\"translate\")\n",
    "    trans_text = result[\"text\"]\n",
    "    print(\"Transcription:\", trans_text)\n",
    "    return trans_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e54dd353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription:  My Lord, Ram has a desire to learn and study a lot. But he sleeps only when he opens a book. At this time, Ram is giving a gift to God. Instead of writing a book to God and reading it, God asks him, can you come and talk to me? Then God tells him about podcast. Since then, Ram sleeps only when he opens a book. He sleeps only when he listens to podcasts. If you are like Ram, save this video and start the podcast I am telling. This is the idea of CEO. He would have asked questions that people who are not able to think of would not ask. This is WTF. He brings top leaders of each industry and brings them all the information in 2 hours. Both are English.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' My Lord, Ram has a desire to learn and study a lot. But he sleeps only when he opens a book. At this time, Ram is giving a gift to God. Instead of writing a book to God and reading it, God asks him, can you come and talk to me? Then God tells him about podcast. Since then, Ram sleeps only when he opens a book. He sleeps only when he listens to podcasts. If you are like Ram, save this video and start the podcast I am telling. This is the idea of CEO. He would have asked questions that people who are not able to think of would not ask. This is WTF. He brings top leaders of each industry and brings them all the information in 2 hours. Both are English.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# record()\n",
    "transcribe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ccb119e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribes():\n",
    "    model_w = whisper.load_model(\"medium\",device=\"cuda\")\n",
    "    result = model_w.transcribe(\"recording.wav\", task=\"translate\")\n",
    "    trans_text = result[\"text\"]\n",
    "    print(\"Transcription:\", trans_text)\n",
    "    return trans_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c2a5ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c54281c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription:  I want to learn a lot from Ram. But he will fall asleep when I open a book. At this time, God gives a gift to Ram. Instead of writing a book to God, he asks me if I can talk to him. God says that he wants a podcast. Since then, Ram has been sleeping listening to podcasts. If you are interested, start the podcast I am talking about. I have a question for people who have not heard the podcast. WTF! He brings the top leaders of every industry and brings the best information in 2 hours. Why is everything in English?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' I want to learn a lot from Ram. But he will fall asleep when I open a book. At this time, God gives a gift to Ram. Instead of writing a book to God, he asks me if I can talk to him. God says that he wants a podcast. Since then, Ram has been sleeping listening to podcasts. If you are interested, start the podcast I am talking about. I have a question for people who have not heard the podcast. WTF! He brings the top leaders of every industry and brings the best information in 2 hours. Why is everything in English?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcribes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b82de785",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\projects\\generative ai\\ai meeting\\myenv\\Lib\\site-packages\\langsmith\\client.py:288: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['agent_scratchpad', 'input'] optional_variables=['chat_history'] input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000021021E527A0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000021021E527A0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]} partial_variables={'chat_history': []} metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')]\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "print(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eed6542a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================ System Message ================================\n",
      "\n",
      "You are a helpful assistant\n",
      "\n",
      "============================= Messages Placeholder =============================\n",
      "\n",
      "{chat_history}\n",
      "\n",
      "================================ Human Message =================================\n",
      "\n",
      "{input}\n",
      "\n",
      "============================= Messages Placeholder =============================\n",
      "\n",
      "{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "print(prompt.pretty_repr())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1db001b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available devices (index: name):\n",
      "0 : Microsoft Sound Mapper - Input IN channels: 2 OUT channels: 0\n",
      "1 : Microphone Array (Realtek(R) Au IN channels: 2 OUT channels: 0\n",
      "2 : Stereo Mix (Realtek(R) Audio) IN channels: 2 OUT channels: 0\n",
      "3 : Microsoft Sound Mapper - Output IN channels: 0 OUT channels: 2\n",
      "4 : Speakers (Realtek(R) Audio) IN channels: 0 OUT channels: 2\n",
      "5 : Primary Sound Capture Driver IN channels: 2 OUT channels: 0\n",
      "6 : Microphone Array (Realtek(R) Audio) IN channels: 2 OUT channels: 0\n",
      "7 : Stereo Mix (Realtek(R) Audio) IN channels: 2 OUT channels: 0\n",
      "8 : Primary Sound Driver IN channels: 0 OUT channels: 2\n",
      "9 : Speakers (Realtek(R) Audio) IN channels: 0 OUT channels: 2\n",
      "10 : Speakers (Realtek(R) Audio) IN channels: 0 OUT channels: 2\n",
      "11 : Microphone Array (Realtek(R) Audio) IN channels: 2 OUT channels: 0\n",
      "12 : Stereo Mix (Realtek(R) Audio) IN channels: 2 OUT channels: 0\n",
      "13 : Microphone (Realtek HD Audio Mic input) IN channels: 2 OUT channels: 0\n",
      "14 : Speakers 1 (Realtek HD Audio output with HAP) IN channels: 0 OUT channels: 2\n",
      "15 : Speakers 2 (Realtek HD Audio output with HAP) IN channels: 0 OUT channels: 2\n",
      "16 : PC Speaker (Realtek HD Audio output with HAP) IN channels: 2 OUT channels: 0\n",
      "17 : Microphone Array (Realtek HD Audio Mic Array input) IN channels: 2 OUT channels: 0\n",
      "18 : Stereo Mix (Realtek HD Audio Stereo input) IN channels: 2 OUT channels: 0\n",
      "19 : Headphones (Realtek HD Audio 2nd output) IN channels: 0 OUT channels: 2\n",
      "Could not auto-find a loopback device. Look for devices with 'loopback' or enable Stereo Mix / use a virtual cable.\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import threading\n",
    "import time\n",
    "\n",
    "DURATION = 10.0  # seconds\n",
    "SR = 48000       # target sample rate (change if your devices require different)\n",
    "CHANNELS_SYS = 2 # usually stereo for system audio\n",
    "CHANNELS_MIC = 1 # typical mic mono (could be 2)\n",
    "\n",
    "def find_wasapi_loopback():\n",
    "    devs = sd.query_devices()\n",
    "    wasapi = sd.query_hostapis()\n",
    "    # Try to find a device with 'loopback' in its name and hostapi = WASAPI\n",
    "    for i, d in enumerate(devs):\n",
    "        name = d['name'].lower()\n",
    "        if 'loopback' in name or 'loop back' in name:\n",
    "            return i, d\n",
    "    # fallback: find devices under WASAPI hostapi and pick one that looks like speakers\n",
    "    for i, d in enumerate(devs):\n",
    "        if d['hostapi'] == sd.default.hostapi:\n",
    "            n = d['name'].lower()\n",
    "            if 'speaker' in n or 'output' in n or 'realtek' in n or 'headphone' in n:\n",
    "                # Many WASAPI devices have a separate loopback device index — you might need to inspect list manually.\n",
    "                # If you don't find explicit loopback, try enabling 'Stereo Mix' or using a virtual cable.\n",
    "                pass\n",
    "    return None, None\n",
    "\n",
    "def choose_devices():\n",
    "    print(\"Available devices (index: name):\")\n",
    "    for i, d in enumerate(sd.query_devices()):\n",
    "        print(i, \":\", d['name'], \"IN channels:\", d['max_input_channels'], \"OUT channels:\", d['max_output_channels'])\n",
    "    # Try auto-find\n",
    "    loop_idx, loop_dev = find_wasapi_loopback()\n",
    "    mic_idx = None\n",
    "    # choose first device with input channels > 0 (not loopback) for mic\n",
    "    for i, d in enumerate(sd.query_devices()):\n",
    "        if d['max_input_channels'] > 0 and i != loop_idx:\n",
    "            mic_idx = i\n",
    "            break\n",
    "    return loop_idx, mic_idx\n",
    "\n",
    "def record_stream(device_idx, channels, samplerate, duration, buffer_list, name):\n",
    "    def callback(indata, frames, time_info, status):\n",
    "        if status:\n",
    "            print(f\"{name} status:\", status)\n",
    "        buffer_list.append(indata.copy())\n",
    "\n",
    "    with sd.InputStream(device=device_idx, channels=channels, samplerate=samplerate,\n",
    "                        blocksize=1024, callback=callback):\n",
    "        sd.sleep(int(duration * 1000))\n",
    "\n",
    "def flatten_buffers(buffers):\n",
    "    if not buffers:\n",
    "        return np.empty((0,0), dtype=np.float32)\n",
    "    return np.vstack(buffers)\n",
    "\n",
    "def main():\n",
    "    loop_idx, mic_idx = choose_devices()\n",
    "    if loop_idx is None:\n",
    "        print(\"Could not auto-find a loopback device. Look for devices with 'loopback' or enable Stereo Mix / use a virtual cable.\")\n",
    "        return\n",
    "    print(\"Using loopback device index:\", loop_idx, \"and mic index:\", mic_idx)\n",
    "\n",
    "    sys_buf = []\n",
    "    mic_buf = []\n",
    "\n",
    "    t1 = threading.Thread(target=record_stream, args=(loop_idx, CHANNELS_SYS, SR, DURATION, sys_buf, \"SYSTEM\"))\n",
    "    t2 = threading.Thread(target=record_stream, args=(mic_idx, CHANNELS_MIC, SR, DURATION, mic_buf, \"MIC\"))\n",
    "\n",
    "    print(\"Starting recording for\", DURATION, \"seconds...\")\n",
    "    t1.start(); t2.start()\n",
    "    t1.join(); t2.join()\n",
    "    print(\"Recording done.\")\n",
    "\n",
    "    sys_audio = flatten_buffers(sys_buf)   # shape (n_frames, CHANNELS_SYS)\n",
    "    mic_audio = flatten_buffers(mic_buf)   # shape (n_frames, CHANNELS_MIC)\n",
    "\n",
    "    # Align lengths\n",
    "    n = min(len(sys_audio), len(mic_audio))\n",
    "    if n == 0:\n",
    "        print(\"No data captured from one of the devices.\")\n",
    "        return\n",
    "    sys_audio = sys_audio[:n]\n",
    "    mic_audio = mic_audio[:n]\n",
    "\n",
    "    # If mic is mono and system is stereo, expand mic to 2 channels or make stereo pair\n",
    "    if mic_audio.ndim == 1:\n",
    "        mic_audio = mic_audio.reshape(-1, 1)\n",
    "    if mic_audio.shape[1] == 1 and sys_audio.shape[1] == 2:\n",
    "        mic_stereo = np.repeat(mic_audio, 2, axis=1)\n",
    "    else:\n",
    "        mic_stereo = mic_audio\n",
    "\n",
    "    # Save a stereo file where left=system, right=mic (simple mapping)\n",
    "    out_stereo = np.zeros((n, 2), dtype=np.float32)\n",
    "    # map system to left channel (mix both system channels if stereo)\n",
    "    out_stereo[:, 0] = sys_audio.mean(axis=1) if sys_audio.shape[1] > 1 else sys_audio[:,0]\n",
    "    # map mic to right channel\n",
    "    out_stereo[:, 1] = mic_stereo[:, 0]\n",
    "\n",
    "    sf.write('system_left_mic_right.wav', out_stereo, SR)\n",
    "    print(\"Wrote system_left_mic_right.wav\")\n",
    "\n",
    "    # Also write a simple mixed mono file (system + mic)\n",
    "    mono_mix = out_stereo.mean(axis=1)\n",
    "    # normalize to avoid clipping\n",
    "    maxv = np.max(np.abs(mono_mix))\n",
    "    if maxv > 0.99:\n",
    "        mono_mix = mono_mix / (maxv + 1e-9)\n",
    "    sf.write('mixed_mono.wav', mono_mix, SR)\n",
    "    print(\"Wrote mixed_mono.wav\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1ac6bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6 (record_audio):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\SELVAGANAPATHI\\anaconda3\\Lib\\threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\SELVAGANAPATHI\\anaconda3\\Lib\\threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\SELVAGANAPATHI\\AppData\\Local\\Temp\\ipykernel_24212\\1579394000.py\", line 19, in record_audio\n",
      "  File \"c:\\Users\\SELVAGANAPATHI\\anaconda3\\Lib\\site-packages\\sounddevice.py\", line 1440, in __init__\n",
      "    _StreamBase.__init__(self, kind='input', wrap_callback='array',\n",
      "  File \"c:\\Users\\SELVAGANAPATHI\\anaconda3\\Lib\\site-packages\\sounddevice.py\", line 909, in __init__\n",
      "    _check(_lib.Pa_OpenStream(self._ptr, iparameters, oparameters,\n",
      "  File \"c:\\Users\\SELVAGANAPATHI\\anaconda3\\Lib\\site-packages\\sounddevice.py\", line 2804, in _check\n",
      "    raise PortAudioError(errormsg, err)\n",
      "sounddevice.PortAudioError: Error opening InputStream: Invalid device [PaErrorCode -9996]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording system (device 2) + mic (device 13) for 10s...\n",
      "Done recording!\n"
     ]
    },
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 54\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Saved: system_mix.wav, mic.wav, mixed.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 54\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[2], line 44\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     41\u001b[0m sys_audio, mic_audio \u001b[38;5;241m=\u001b[39m sys_audio[:n], mic_audio[:n]\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Mix both (average) into a mono file\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m mix \u001b[38;5;241m=\u001b[39m (sys_audio\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m mic_audio\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     45\u001b[0m mix \u001b[38;5;241m=\u001b[39m mix \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(np\u001b[38;5;241m.\u001b[39mabs(mix))  \u001b[38;5;66;03m# normalize\u001b[39;00m\n\u001b[0;32m     47\u001b[0m sf\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem_mix.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m, sys_audio, SR)\n",
      "File \u001b[1;32mc:\\Users\\SELVAGANAPATHI\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:106\u001b[0m, in \u001b[0;36m_mean\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m    102\u001b[0m arr \u001b[38;5;241m=\u001b[39m asanyarray(a)\n\u001b[0;32m    104\u001b[0m is_float16_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m rcount \u001b[38;5;241m=\u001b[39m _count_reduce_items(arr, axis, keepdims\u001b[38;5;241m=\u001b[39mkeepdims, where\u001b[38;5;241m=\u001b[39mwhere)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rcount \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m where \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m umr_any(rcount \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    108\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean of empty slice.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\SELVAGANAPATHI\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:77\u001b[0m, in \u001b[0;36m_count_reduce_items\u001b[1;34m(arr, axis, keepdims, where)\u001b[0m\n\u001b[0;32m     75\u001b[0m     items \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m axis:\n\u001b[1;32m---> 77\u001b[0m         items \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mshape[mu\u001b[38;5;241m.\u001b[39mnormalize_axis_index(ax, arr\u001b[38;5;241m.\u001b[39mndim)]\n\u001b[0;32m     78\u001b[0m     items \u001b[38;5;241m=\u001b[39m nt\u001b[38;5;241m.\u001b[39mintp(items)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;66;03m# TODO: Optimize case when `where` is broadcast along a non-reduction\u001b[39;00m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;66;03m# axis and full sum is more excessive than needed.\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \n\u001b[0;32m     83\u001b[0m     \u001b[38;5;66;03m# guarded to protect circular imports\u001b[39;00m\n",
      "\u001b[1;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import threading\n",
    "\n",
    "# --- Choose your devices here ---\n",
    "SYSTEM_AUDIO_DEVICE = 2   # Stereo Mix (Realtek)\n",
    "MIC_AUDIO_DEVICE = 13     # Microphone (Realtek HD Audio Mic input)\n",
    "SR = 44100                # Common sample rate\n",
    "DURATION = 10             # seconds\n",
    "# --------------------------------\n",
    "\n",
    "def record_audio(device_idx, channels, samplerate, duration, buffer_list, label):\n",
    "    def callback(indata, frames, time_info, status):\n",
    "        if status:\n",
    "            print(f\"{label} status:\", status)\n",
    "        buffer_list.append(indata.copy())\n",
    "\n",
    "    with sd.InputStream(device=device_idx, channels=channels, samplerate=samplerate, callback=callback):\n",
    "        sd.sleep(int(duration * 1000))\n",
    "\n",
    "def flatten(buffers):\n",
    "    return np.vstack(buffers) if buffers else np.empty((0,))\n",
    "\n",
    "def main():\n",
    "    sys_buf = []\n",
    "    mic_buf = []\n",
    "\n",
    "    sys_thread = threading.Thread(target=record_audio, args=(SYSTEM_AUDIO_DEVICE, 2, SR, DURATION, sys_buf, \"SYSTEM\"))\n",
    "    mic_thread = threading.Thread(target=record_audio, args=(MIC_AUDIO_DEVICE, 2, SR, DURATION, mic_buf, \"MIC\"))\n",
    "\n",
    "    print(f\"Recording system (device {SYSTEM_AUDIO_DEVICE}) + mic (device {MIC_AUDIO_DEVICE}) for {DURATION}s...\")\n",
    "    sys_thread.start(); mic_thread.start()\n",
    "    sys_thread.join(); mic_thread.join()\n",
    "    print(\"Done recording!\")\n",
    "\n",
    "    sys_audio = flatten(sys_buf)\n",
    "    mic_audio = flatten(mic_buf)\n",
    "\n",
    "    n = min(len(sys_audio), len(mic_audio))\n",
    "    sys_audio, mic_audio = sys_audio[:n], mic_audio[:n]\n",
    "\n",
    "    # Mix both (average) into a mono file\n",
    "    mix = (sys_audio.mean(axis=1) + mic_audio.mean(axis=1)) / 2\n",
    "    mix = mix / np.max(np.abs(mix))  # normalize\n",
    "\n",
    "    sf.write(\"system_mix.wav\", sys_audio, SR)\n",
    "    sf.write(\"mic.wav\", mic_audio, SR)\n",
    "    sf.write(\"mixed.wav\", mix, SR)\n",
    "\n",
    "    print(\"✅ Saved: system_mix.wav, mic.wav, mixed.wav\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65b4a4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : Microsoft Sound Mapper - Input | 0 | IN: 2 OUT: 0\n",
      "1 : Microphone Array (Realtek(R) Au | 0 | IN: 2 OUT: 0\n",
      "2 : Stereo Mix (Realtek(R) Audio) | 0 | IN: 2 OUT: 0\n",
      "3 : Microsoft Sound Mapper - Output | 0 | IN: 0 OUT: 2\n",
      "4 : Speakers (Realtek(R) Audio) | 0 | IN: 0 OUT: 2\n",
      "5 : Primary Sound Capture Driver | 1 | IN: 2 OUT: 0\n",
      "6 : Microphone Array (Realtek(R) Audio) | 1 | IN: 2 OUT: 0\n",
      "7 : Stereo Mix (Realtek(R) Audio) | 1 | IN: 2 OUT: 0\n",
      "8 : Primary Sound Driver | 1 | IN: 0 OUT: 2\n",
      "9 : Speakers (Realtek(R) Audio) | 1 | IN: 0 OUT: 2\n",
      "10 : Speakers (Realtek(R) Audio) | 2 | IN: 0 OUT: 2\n",
      "11 : Microphone Array (Realtek(R) Audio) | 2 | IN: 2 OUT: 0\n",
      "12 : Stereo Mix (Realtek(R) Audio) | 2 | IN: 2 OUT: 0\n",
      "13 : Microphone (Realtek HD Audio Mic input) | 3 | IN: 2 OUT: 0\n",
      "14 : Speakers 1 (Realtek HD Audio output with HAP) | 3 | IN: 0 OUT: 2\n",
      "15 : Speakers 2 (Realtek HD Audio output with HAP) | 3 | IN: 0 OUT: 2\n",
      "16 : PC Speaker (Realtek HD Audio output with HAP) | 3 | IN: 2 OUT: 0\n",
      "17 : Microphone Array (Realtek HD Audio Mic Array input) | 3 | IN: 2 OUT: 0\n",
      "18 : Stereo Mix (Realtek HD Audio Stereo input) | 3 | IN: 2 OUT: 0\n",
      "19 : Headphones (Realtek HD Audio 2nd output) | 3 | IN: 0 OUT: 2\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "for i, d in enumerate(sd.query_devices()):\n",
    "    print(i, \":\", d['name'], \"|\", d['hostapi'], \"| IN:\", d['max_input_channels'], \"OUT:\", d['max_output_channels'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f085046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Stereo Mix at index 1 : Stereo Mix (Realtek(R) Audio)\n",
      "Recording from Stereo Mix...\n",
      "Saved system_plus_mic.wav\n"
     ]
    }
   ],
   "source": [
    "#ithu ok\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "\n",
    "device_name = None\n",
    "for i, d in enumerate(sd.query_devices()):\n",
    "    if \"stereo mix\" in d['name'].lower():\n",
    "        device_name = i\n",
    "        print(\"Found Stereo Mix at index\", i, \":\", d['name'])\n",
    "        break\n",
    "\n",
    "if device_name is None:\n",
    "    raise RuntimeError(\"Stereo Mix device not found\")\n",
    "\n",
    "# Then use it in the recording\n",
    "SR = 44100\n",
    "DURATION = 10\n",
    "\n",
    "print(\"Recording from Stereo Mix...\")\n",
    "data = sd.rec(int(DURATION*SR), samplerate=SR, channels=2, device=DEVICE_IDX)\n",
    "sd.wait()\n",
    "\n",
    "# Normalize to avoid clipping\n",
    "data = data / np.max(np.abs(data))\n",
    "\n",
    "sf.write(\"system_plus_mic.wav\", data, SR)\n",
    "print(\"Saved system_plus_mic.wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c15b0d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Stereo Mix at index 1 : Stereo Mix (Realtek(R) Audio)\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "\n",
    "# Look for a device that contains \"Stereo Mix\" in the name\n",
    "device_name = None\n",
    "for i, d in enumerate(sd.query_devices()):\n",
    "    if \"stereo mix\" in d['name'].lower():\n",
    "        device_name = i\n",
    "        print(\"Found Stereo Mix at index\", i, \":\", d['name'])\n",
    "        break\n",
    "\n",
    "if device_name is None:\n",
    "    raise RuntimeError(\"Stereo Mix device not found\")\n",
    "\n",
    "# Then use it in the recording\n",
    "SR = 44100\n",
    "DURATION = 10\n",
    "data = sd.rec(int(DURATION*SR), samplerate=SR, channels=2, device=device_name)\n",
    "sd.wait()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddc26848",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sd\u001b[38;5;241m.\u001b[39mquery_devices()):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstereo mix\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mlower():\n\u001b[0;32m      3\u001b[0m         device_idx \u001b[38;5;241m=\u001b[39m i\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sd' is not defined"
     ]
    }
   ],
   "source": [
    "for i, d in enumerate(sd.query_devices()):\n",
    "    if \"stereo mix\" in d[\"name\"].lower():\n",
    "        device_idx = i\n",
    "        print(f\"✅ Found Stereo Mix at index {i}: {d['name']}\")\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
